---
hide: toc
---
# Artikel 3 - Definities

Voor de toepassing van deze verordening wordt verstaan onder:

1. “AI-systeem”: een op een machine gebaseerd systeem dat is ontworpen om met verschillende niveaus van autonomie te
   werken en dat na het inzetten ervan aanpassingsvermogen kan vertonen, en dat, voor expliciete of impliciete
   doelstellingen, uit de ontvangen input afleidt hoe output te genereren zoals voorspellingen, inhoud, aanbevelingen of
   beslissingen die van invloed kunnen zijn op fysieke of virtuele omgevingen;
2. “risico”: de combinatie van de kans op schade en de ernst van die schade;
3. “aanbieder”: een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem
   of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt
   of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling;
4. “gebruiksverantwoordelijke”: een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat
   een AI-systeem onder eigen verantwoordelijkheid gebruikt, tenzij het AI-systeem wordt gebruikt in het kader van een
   persoonlijke niet-beroepsactiviteit;
5. “gemachtigde”: een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een schriftelijke
   machtiging heeft gekregen en aanvaard van een aanbieder van een AI-systeem of een AI-model voor algemene doeleinden
   om namens die aanbieder de verplichtingen en procedures van deze verordening respectievelijk na te komen en uit te
   voeren;
6. “importeur”: een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een AI-systeem in de
   handel brengt dat de naam of het merk van een in een derde land gevestigde natuurlijke of rechtspersoon draagt;
7. “distributeur”: een andere natuurlijke persoon of rechtspersoon in de toeleveringsketen dan de aanbieder of de
   importeur, die een AI-systeem in de Unie op de markt aanbiedt;
8. “operator”: een aanbieder, productfabrikant, gebruiksverantwoordelijke, gemachtigde, importeur of distributeur;
9. “in de handel brengen”: het voor het eerst in de Unie op de markt aanbieden van een AI-systeem of een AI-model voor
   algemene doeleinden;
10. “op de markt aanbieden”: het in het kader van een handelsactiviteit, al dan niet tegen betaling, verstrekken van
    een AI-systeem of een AI-model voor algemene doeleinden met het oog op distributie of gebruik op de markt van de
    Unie;
11. “in gebruik stellen”: de directe levering van een AI-systeem aan de gebruiksverantwoordelijke voor het eerste
    gebruik of voor eigen gebruik in de Unie voor het beoogde doel;
12. “beoogd doel”: het gebruik waarvoor een AI-systeem door de aanbieder is bedoeld, met inbegrip van de specifieke
    context en voorwaarden van het gebruik, zoals gespecificeerd in de informatie die door de aanbieder in de
    gebruiksinstructies, reclame- of verkoopmaterialen en verklaringen, alsook in de technische documentatie is
    verstrekt;
13. “redelijkerwijs te voorzien misbruik”: het gebruik van een AI-systeem op een wijze die niet in overeenstemming is
    met het beoogde doel, maar die kan voortvloeien uit redelijkerwijs te voorzien menselijk gedrag of redelijkerwijs te
    voorziene interactie met andere systemen, waaronder andere AI-systeem;
14. “veiligheidscomponent”: een component van een product of van een AI-systeem die een veiligheids-functie voor dat
    product of AI-systeem vervult of waarvan het falen of gebrekkig functioneren de gezondheid en veiligheid van
    personen of eigendom in gevaar brengt;
15. “gebruiksinstructies”: de door de aanbieder verstrekte informatie om de gebruiksverantwoordelijke te informeren over
    met name het beoogde doel en juiste gebruik van een AI-systeem;
16. “terugroepen van een AI-systeem”: een maatregel gericht op het retourneren aan de aanbieder, het buiten gebruik
    stellen of het onbruikbaar maken van een AI-systeem dat aan gebruiksverantwoordelijken ter beschikking is gesteld;
17. “uit de handel nemen van een AI-systeem”: een maatregel waarmee wordt beoogd te voorkomen dat een AI-systeem dat
    zich in de toeleveringsketen bevindt, op de markt wordt aangeboden;
18. “prestaties van een AI-systeem”: het vermogen van een AI-systeem om het beoogde doel te verwezenlijken;
19. “aanmeldende autoriteit”: de nationale autoriteit die verantwoordelijk is voor het opzetten en uitvoeren van de
    noodzakelijke procedures voor de beoordeling, aanwijzing en kennisgeving van de conformiteitsbeoordelingsinstantie
    en de monitoring hiervan;
20. “conformiteitsbeoordeling”: het proces waarbij de naleving wordt aangetoond van de voorschriften van hoofdstuk III,
    afdeling 2, in verband met een AI-systeem met een hoog risico;
21. “conformiteitsbeoordelingsinstantie”: een instantie die als derde partij conformiteits-beoordelingsactiviteiten
    verricht, zoals onder meer testen, certificeren en inspecteren;
22. “aangemelde instantie”: een conformiteitsbeoordelingsinstantie die overeenkomstig deze verordening en andere
    relevante harmonisatiewetgeving van de Unie, is aangemeld;
23. “substantiële wijziging”: een verandering van een AI-systeem nadat dit in de handel is gebracht of in gebruik is
    gesteld, die door de aanbieder niet is voorzien of gepland in de initiële conformiteitsbeoordeling en als gevolg
    waarvan de overeenstemming van het AI-systeem met de voorschriften van hoofdstuk III, afdeling 2, wordt beïnvloed,
    of die leidt tot een wijziging van het beoogde doel waarvoor het AI-systeem is beoordeeld;
24. “CE-markering”: een markering waarmee een aanbieder aangeeft dat een AI-systeem in overeenstemming is met de
    voorschriften van hoofdstuk III, afdeling 2, en andere toepasselijke harmonisatiewetgeving van de Unie, die in het
    aanbrengen ervan voorzien;
25. “systeem voor monitoring na het in de handel brengen”: alle door aanbieders van AI-systeem verrichte activiteiten
    voor het verzamelen en evalueren van ervaringen met door hen in de handel gebrachte of in gebruik gestelde
    AI-systeem, teneinde te kunnen vaststellen of er onmiddellijk corrigerende dan wel preventieve maatregelen nodig
    zijn;
26. “markttoezichtautoriteit”: de nationale autoriteit die de activiteiten verricht en maatregelen neemt als bedoeld in
    Verordening (EU) 2019/1020;
27. “geharmoniseerde norm”: een geharmoniseerde norm zoals gedefinieerd in artikel 2, lid 1, punt c), van Verordening
    (EU) nr. 1025/2012;
28. “gemeenschappelijke specificatie”: een reeks technische specificaties zoals gedefinieerd in artikel 2, punt 4, van
    Verordening (EU) nr. 1025/2012, om te voldoen aan bepaalde voorschriften zoals vastgelegd in deze verordening;
29. “trainingsdata”: data die worden gebruikt voor het trainen van een AI-systeem door de leerbare parameters hiervan
    aan te passen;
30. “validatiedata”: data die worden gebruikt voor het verrichten van een evaluatie van het getrainde AI-systeem en voor
    het afstemmen van onder andere de niet-leerbare parameters en het leerproces ervan, om underfitting of overfitting
    te voorkomen;
31. “validatiedataset”: een afzonderlijke dataset of deel van de trainingsdataset, als vaste of variabele opdeling;
32. “testdata”: data die worden gebruikt voor het verrichten van een onafhankelijke evaluatie van het AI-systeem om de
    verwachte prestaties van dat systeem te bevestigen voordat het in de handel wordt gebracht of in gebruik wordt
    gesteld;
33. “inputdata”: data die in een AI-systeem worden ingevoerd of direct door een AI-systeem worden verworven en op basis
    waarvan het systeem een output genereert;
34. “biometrische gegevens”: persoonsgegevens die het resultaat zijn van een specifieke technische verwerking met
    betrekking tot de fysieke, fysiologische of gedragsgerelateerde kenmerken van een natuurlijk persoon, zoals
    gezichtsafbeeldingen of vingerafdrukgegevens;
35. “biometrische identificatie”: de geautomatiseerde herkenning van fysieke, fysiologische, gedragsgerelateerde of
    psychologische menselijke kenmerken om de identiteit van een natuurlijk persoon vast te stellen door biometrische
    gegevens van die persoon te vergelijken met in een databank opgeslagen biometrische gegevens van personen;
36. “biometrische verificatie”: de geautomatiseerde één-op-éénverificatie, met inbegrip van de authenticatie, van de
    identiteit van natuurlijke personen door hun biometrische gegevens te vergelijken met eerder verstrekte biometrische
    gegevens;
37. “bijzondere categorieën persoonsgegevens”: de categorieën persoonsgegevens als bedoeld in artikel 9, lid 1, van
    Verordening (EU) 2016/679, artikel 10 van Richtlijn (EU) 2016/680 en artikel 10, lid 1, van Verordening (EU)
    2018/1725;
38. “gevoelige operationele gegevens”: operationele gegevens met betrekking tot activiteiten op het gebied van
    preventie, opsporing, onderzoek of vervolging van strafbare feiten waarvan de openbaarmaking de integriteit van
    strafprocedures in het gedrang zou kunnen brengen;
39. “systeem voor het herkennen van emoties”: een AI-systeem dat is bedoeld voor het vaststellen of afleiden van de
    emoties of intenties van natuurlijke personen op basis van hun biometrische gegevens;
40. “systeem voor biometrische categorisering” een AI-systeem dat is bedoeld voor het indelen van natuurlijke personen
    in specifieke categorieën op basis van hun biometrische gegevens, tenzij dit een aanvulling vormt op een andere
    commerciële dienst en om objectieve technische redenen strikt noodzakelijk is;
41. “systeem voor biometrische identificatie op afstand”: een AI-systeem dat is bedoeld voor het identificeren van
    natuurlijke personen, zonder dat zij daar actief bij betrokken zijn en doorgaans van een afstand, door middel van
    vergelijking van de biometrische gegevens van een persoon met de biometrische gegevens die zijn opgenomen in een
    referentiedatabank;
42. “systeem voor biometrische identificatie op afstand in real time”: een systeem voor biometrische identificatie op
    afstand, waarbij het vastleggen van biometrische gegevens, de vergelijking en de identificatie zonder significante
    vertraging plaatsvinden, zowel wanneer de identificatie niet enkel onmiddellijk plaatsvindt, maar ook wanneer de
    identificatie met beperkte korte vertragingen plaatsvindt, om omzeiling te voorkomen;
43. “systeem voor biometrische identificatie op afstand achteraf”: een ander biometrisch systeem voor de identificatie
    op afstand dan een systeem voor biometrische identificatie op afstand in real time;
44. “openbare ruimte”: een fysieke plek die in publieke of private handen is en toegankelijk is voor een onbepaald
    aantal natuurlijke personen, ongeacht of bepaalde voorwaarden voor de toegang van toepassing zijn, en ongeacht
    eventuele capaciteitsbeperkingen;
45. “rechtshandhavingsinstantie”:
    1. iedere overheidsinstantie die bevoegd is voor de voorkoming van, het onderzoek naar, de opsporing en de
       vervolging van strafbare feiten of de uitvoering van straffen, met inbegrip van de bescherming tegen en de
       voorkoming van gevaren voor de openbare veiligheid, of
    2. ieder ander orgaan dat of iedere andere entiteit die krachtens het recht van de lidstaten is gemachtigd
       openbaar gezag en openbare bevoegdheden uit te oefenen met het oog op de voorkoming van, het onderzoek naar, de
       opsporing en de vervolging van strafbare feiten of de uitvoering van straffen, met inbegrip van de bescherming
       tegen en de voorkoming van gevaren voor de openbare veiligheid;
46. “rechtshandhaving”: activiteiten die worden verricht door of namens rechtshandhavings-instanties met het oog op de
    voorkoming van, het onderzoek naar, de opsporing of de vervolging van strafbare feiten of de uitvoering van
    straffen, met inbegrip van de bescherming tegen en de voorkoming van gevaren voor de openbare veiligheid;
47. “AI-bureau”: de taak van de Commissie waarbij zij bijdraagt aan de uitvoering van, de monitoring van en het toezicht
    op AI-systeem en AI-modellen voor algemene doeleinden, en AI-governance, als bepaald in het besluit van de Commissie
    van 24 januari 2024; verwijzingen in deze verordening naar het AI-bureau worden begrepen als verwijzingen naar de
    Commissie;
48. “nationale bevoegde autoriteit”: een aanmeldende autoriteit of een de markttoezichtautoriteit; wat betreft
    AI-systeem die door instellingen, organen en instanties van de EU in gebruik worden gesteld of worden gebruikt,
    worden verwijzingen naar nationale bevoegde autoriteiten of markttoezichtautoriteiten in deze verordening begrepen
    als verwijzingen naar de Europese Toezichthouder voor gegevensbescherming;
49. “ernstig incident”: een incident of gebrekkig functioneren van een AI-systeem dat direct of indirect leidt tot:
    1. het overlijden van een persoon of ernstige schade voor de gezondheid van een persoon;
    2. een ernstige en onomkeerbare verstoring van het beheer of de exploitatie van kritieke infrastructuur;
    3. een schending van de uit het recht van de Unie voortvloeiende verplichtingen ter bescherming van de
       grondrechten;
    4. ernstige schade aan eigendommen of het milieu;
50. “persoonsgegevens”: persoonsgegevens zoals gedefinieerd in artikel 4, punt 1, van Verordening (EU) 2016/679;
51. “niet-persoonsgebonden gegevens”: andere gegevens dan persoonsgegevens zoals gedefinieerd in artikel 4, punt 1, van
    Verordening (EU) 2016/679;
52. “profilering”: profilering zoals gedefinieerd in artikel 4, punt 4, van Verordening (EU) 2016/679;
53. “plan voor testen onder reële omstandigheden”: een document waarin de doelstellingen, methode, geografische
    reikwijdte, betrokken personen, duur, monitoring, organisatie en wijze van uitvoering van een test onder reële
    omstandigheden worden omschreven;
54. “testomgevingsplan”: tussen de deelnemende aanbieder en de bevoegde autoriteit overeengekomen document waarin de
    doelstellingen, de voorwaarden, het tijdschema, de methode en de vereisten voor de in de testomgeving uitgevoerde
    activiteiten worden beschreven;
55. “AI-testomgeving voor regelgeving”: een door een bevoegde autoriteit opgezet gecontroleerd kader dat aanbieders of
    toekomstige aanbieders van AI-systeem de mogelijkheid biedt een innovatief AI-systeem te ontwikkelen, trainen,
    valideren en testen, zo nodig onder reële omstandigheden, volgens een testomgevingsplan, voor een beperkte periode
    en onder begeleiding van een toezichthouder;
56. “AI-geletterdheid”: vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen,
    rekening houdend met hun respectieve rechten en plichten in het kader van deze verordening, in staat stellen
    geïnformeerd AI-systeem in te zetten en zich bewuster te worden van de kansen en risico’s van AI en de mogelijke
    schade die zij kan veroorzaken;
57. “testen onder reële omstandigheden”: het tijdelijk testen van een AI-systeem voor zijn beoogde doel onder reële
    omstandigheden buiten een laboratorium of anderszins gesimuleerde omgeving teneinde betrouwbare en robuuste gegevens
    te verkrijgen, en te beoordelen en te verifiëren of het AI-systeem overeenstemt met de voorschriften van deze
    verordening en het wordt niet aangemerkt als het in de handel brengen of in gebruik stellen van het AI-systeem in de
    zin van deze verordening, mits aan alle in artikel 57 of artikel 60 vastgestelde voorwaarden is voldaan;
58. “proefpersoon” in het kader van tests onder reële omstandigheden: een natuurlijk persoon die deelneemt aan een test
    onder reële omstandigheden;
59. “geïnformeerde toestemming”: de vrijelijk gegeven, specifieke, ondubbelzinnige en vrijwillige uiting door een
    proefpersoon van zijn of haar bereidheid deel te nemen aan een bepaalde test onder reële omstandigheden, na
    geïnformeerd te zijn over alle aspecten van de test die van belang zijn voor zijn of haar beslissing om deel te
    nemen;
60. “deepfake”: door AI gegenereerd of gemanipuleerd beeld-, audio- of videomateriaal dat een gelijkenis vertoont met
    bestaande personen, voorwerpen, plaatsen, entiteiten of gebeurtenissen, en door een persoon ten onrechte voor
    authentiek of waarheidsgetrouw zou worden aangezien;
61. “wijdverbreide inbreuk”: alle handelingen of omissies die in strijd zijn met het Unierecht ter bescherming van de
    belangen van natuurlijke personen, waarbij:
    1. schade is veroorzaakt of waarschijnlijk zal worden veroorzaakt aan de collectieve belangen van natuurlijke
       personen met verblijfplaats in ten minste twee andere lidstaten dan de lidstaat waar:
        1. de handeling of omissie haar oorsprong vond of plaatshad;
        2. de betrokken aanbieder of, waar van toepassing, diens gemachtigde zich bevindt of is gevestigd, of
        3. de gebruiksverantwoordelijke is gevestigd, indien de inbreuk door de gebruiksverantwoordelijke is
           gepleegd;
    2. schade is veroorzaakt, wordt veroorzaakt of waarschijnlijk zal worden veroorzaakt aan de collectieve belangen
       van natuurlijke personen, en die gemeenschappelijke kenmerken hebben, waaronder dezelfde onrechtmatige praktijk
       of een inbreuk op hetzelfde belang, en die zich gelijktijdig voordoen en door dezelfde operator worden begaan in
       ten minste drie lidstaten;
62. “kritieke infrastructuur”: kritieke infrastructuur zoals gedefinieerd in artikel 2, punt 4, van Richtlijn (EU)
    2022/2557;
63. “AI-model voor algemene doeleinden”: een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met
    behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op
    competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de
    handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de
    AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt
    voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht;
64. “capaciteiten met een grote impact”: capaciteiten die overeenkomen met of groter zijn dan de capaciteiten die worden
    opgetekend bij de meest geavanceerde AI-modellen voor algemene doeleinden;
65. “systeemrisico”: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene
    doeleinden, die aanzienlijke gevolgen hebben voor de markt van de Unie vanwege hun bereik, of vanwege feitelijke of
    redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de
    grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid;
66. “AI-systeem voor algemene doeleinden”: een AI-systeem dat is gebaseerd op een AI-model voor algemene doeleinden en
    dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systeem;
67. zwevendekommabewerking of “floating-point operation (FLOP)”: elke wiskundige bewerking of toewijzing met
    zwevendekommagetallen, die een subset vormen van de reële getallen die gewoonlijk op computers worden
    gerepresenteerd door een geheel getal met een vaste precisie, geschaald door een gehele exponent van een vaste
    basis;
68. “aanbieder verder in de AI-waardeketen”: een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor
    algemene doeleinden, waarin een AI-model is geïntegreerd, ongeacht of het AI-model door hemzelf wordt verstrekt en
    verticaal geïntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen.
