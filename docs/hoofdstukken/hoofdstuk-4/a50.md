## Artikel 50 Transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken van bepaalde AI-systeem

1. aanbieders zorgen ervoor dat AI-systeem die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden geïnformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geïnformeerde en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext. Deze verplichting is niet van toepassing op bij wet toegestane AI-systeem voor het opsporen, voorkomen, onderzoeken of vervolgen van strafbare feiten, met inachtneming van passende waarborgen voor de rechten en vrijheden van derden, tenzij die systemen voor het publiek beschikbaar zijn om een strafbaar feit te melden.
2. aanbieders van AI-systeem, met inbegrip van AI-systeem voor algemene doeleinden, die synthetische audio-, beeld-, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel, robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen. Deze verplichting is niet van toepassing voor zover de AI-systeem een ondersteunende functie voor standaardbewerking vervullen of de door de gebruiksverantwoordelijke of de semantiek daarvan verstrekte inputdata niet substantieel wijzigen, of wanneer het bij wet is toegestaan strafbare feiten op te sporen, te voorkomen, te onderzoeken of te vervolgen.
3. gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing. Deze verplichting is niet van toepassing op voor biometrische categorisering en emotieherkenning gebruikte AI-systeem, die bij wet zijn toegestaan om strafbare feiten op te sporen, te voorkomen of te onderzoeken, met inachtneming van passende waarborgen voor de rechten en vrijheden van derden en overeenkomstig het Unierecht.
4. gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Deze verplichting geldt niet wanneer het gebruik bij wet is toegestaan om strafbare feiten op te sporen, te voorkomen, te onderzoeken of te vervolgen. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen van dit lid beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.
   gebruiksverantwoordelijken van een AI-systeem dat tekst genereert of bewerkt die wordt gepubliceerd om het publiek te informeren over aangelegenheden van algemeen belang, maken bekend dat de tekst kunstmatig is gegenereerd of bewerkt. Deze verplichting is echter niet van toepassing wanneer het gebruik bij wet is toegestaan om strafbare feiten op te sporen, te voorkomen, te onderzoeken of te vervolgen of wanneer de door AI gegenereerde content een proces van menselijke toetsing of redactionele controle heeft ondergaan en wanneer een natuurlijke of rechtspersoon redactionele verantwoordelijkheid draagt voor de bekendmaking van de content.
5. De in de leden 1 tot en met 4 bedoelde informatie wordt uiterlijk op het moment van de eerste interactie of blootstelling op duidelijke en te onderscheiden wijze aan de betrokken natuurlijke personen verstrekt. De informatie moet aan de toepasselijke toegankelijkheidseisen voldoen.
6. De leden 1 tot en met 4 laten de voorschriften en verplichtingen van hoofdstuk III onverlet en doen geen afbreuk aan andere transparantieverplichtingen die zijn vastgelegd in het Unierecht of het nationale recht voor gebruiksverantwoordelijken van AI-systeem.
7. Het AI-bureau stimuleert en faciliteert de opstelling van praktijkcodes op het niveau van de Unie om de doeltreffende uitvoering van de verplichtingen met betrekking tot de opsporing en het labelen van kunstmatig gegenereerde of bewerkte content te vergemakkelijken. De Commissie kan uitvoeringshandelingen vaststellen om die praktijkcodes overeenkomstig de procedure van artikel 56, lid 6, goed te keuren. Indien zij de code ontoereikend acht, kan de Commissie volgens de onderzoeksprocedure van artikel 98, lid 2, een uitvoeringshandeling vaststellen waarin gemeenschappelijke regels voor de uitvoering van die verplichtingen worden gespecificeerd.
